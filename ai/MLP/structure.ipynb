{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  print out structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mycrograd.engine import Value\n",
    "from mycrograd.nn import Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of inputs:  3\n",
      "Neuron(2):  ReLUNeuron(3)\n",
      "weights:  [Value(data=0.5808552090645627, grad=0), Value(data=0.09921848842252134, grad=0), Value(data=0.5519936528601597, grad=0)]\n",
      "b:  Value(data=0, grad=0)\n",
      "number of parameters  4\n",
      "inputs  [8 5 2]\n",
      "activation:  Value(data=6.246921420349428, grad=0)\n"
     ]
    }
   ],
   "source": [
    "nin=3\n",
    "myNeuron=Neuron(nin)\n",
    "print(\"number of inputs: \",nin)\n",
    "print(\"Neuron(2): \",myNeuron)\n",
    "print(\"weights: \",myNeuron.w)\n",
    "print(\"b: \",myNeuron.b)\n",
    "print(\"number of parameters \", len(myNeuron.parameters()))\n",
    "# xi=[1,2,3,4]\n",
    "xi= np.random.randint(1,10, size=(nin))\n",
    "print(\"inputs \", xi)\n",
    "print(\"activation: \",myNeuron(xi))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23716815 -0.17338508]\n",
      " [-0.55222318  0.57003313]\n",
      " [ 1.14252914 -0.02794639]\n",
      " [-1.05596279  0.11863834]\n",
      " [ 0.16985189  0.33087798]\n",
      " [-0.06995228  1.05829628]\n",
      " [ 0.80492904  0.58536957]\n",
      " [ 1.86706046  0.49985453]\n",
      " [ 1.57564151 -0.24506796]\n",
      " [ 1.12652106 -0.48793323]]\n",
      "[1 0 0 0 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# make up a dataset\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "X, y = make_moons(n_samples=10, noise=0.1)\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "y = y*2 - 1 # make y be -1 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "number of parameters 41\n"
     ]
    }
   ],
   "source": [
    "# initialize a model \n",
    "model = MLP(3, [4, 4, 1]) # 2-layer neural network\n",
    "print(model)\n",
    "print(\"number of parameters\", len(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.16635789865605816, grad=0), Value(data=0.8407527318533012, grad=0), Value(data=0.3650390698290702, grad=0), Value(data=0.5671592353200772, grad=0), Value(data=0.3247909568456104, grad=0), Value(data=1.198570856767975, grad=0), Value(data=0.4431939245336829, grad=0), Value(data=0.3485481582055579, grad=0), Value(data=0.6150511532492101, grad=0), Value(data=0.6087682186298902, grad=0)]\n",
      "[Value(data=0.16635789865605816, grad=0), Value(data=0.8407527318533012, grad=0), Value(data=0.3650390698290702, grad=0), Value(data=0.5671592353200772, grad=0), Value(data=0.3247909568456104, grad=0), Value(data=1.198570856767975, grad=0), Value(data=0.4431939245336829, grad=0), Value(data=0.3485481582055579, grad=0), Value(data=0.6150511532492101, grad=0), Value(data=0.6087682186298902, grad=0)]\n",
      "Value(data=1.1361154948345775, grad=0) 0.5\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "def loss(batch_size=None):\n",
    "    \n",
    "    # inline DataLoader :)\n",
    "    if batch_size is None:\n",
    "        Xb, yb = X, y\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X[ri], y[ri]\n",
    "    inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    print(model)\n",
    "    print(inputs)\n",
    "    print(list(map(model, inputs)))\n",
    "    print(scores)\n",
    "\n",
    "    # svm \"max-margin\" loss\n",
    "    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "total_loss, acc = loss()\n",
    "print(total_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.16635789865605816, grad=0), Value(data=0.8407527318533012, grad=0), Value(data=0.3650390698290702, grad=0), Value(data=0.5671592353200772, grad=0), Value(data=0.3247909568456104, grad=0), Value(data=1.198570856767975, grad=0), Value(data=0.4431939245336829, grad=0), Value(data=0.3485481582055579, grad=0), Value(data=0.6150511532492101, grad=0), Value(data=0.6087682186298902, grad=0)]\n",
      "[Value(data=0.16635789865605816, grad=0), Value(data=0.8407527318533012, grad=0), Value(data=0.3650390698290702, grad=0), Value(data=0.5671592353200772, grad=0), Value(data=0.3247909568456104, grad=0), Value(data=1.198570856767975, grad=0), Value(data=0.4431939245336829, grad=0), Value(data=0.3485481582055579, grad=0), Value(data=0.6150511532492101, grad=0), Value(data=0.6087682186298902, grad=0)]\n",
      "step 0 loss 1.1361154948345775, accuracy 50.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.5082031168630629, grad=0), Value(data=0.0282435236702223, grad=0), Value(data=0.9497277420480732, grad=0), Value(data=-0.010548810867934293, grad=0), Value(data=0.05994215126787182, grad=0), Value(data=0.19317933390073616, grad=0), Value(data=0.20536112539404336, grad=0), Value(data=1.0110128060193027, grad=0), Value(data=1.3644682232595353, grad=0), Value(data=1.2666314242340784, grad=0)]\n",
      "[Value(data=0.5082031168630629, grad=0), Value(data=0.0282435236702223, grad=0), Value(data=0.9497277420480732, grad=0), Value(data=-0.010548810867934293, grad=0), Value(data=0.05994215126787182, grad=0), Value(data=0.19317933390073616, grad=0), Value(data=0.20536112539404336, grad=0), Value(data=1.0110128060193027, grad=0), Value(data=1.3644682232595353, grad=0), Value(data=1.2666314242340784, grad=0)]\n",
      "step 1 loss 0.7807478419838042, accuracy 60.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=-0.025766772598165885, grad=0), Value(data=-0.415140955489184, grad=0), Value(data=0.22275505231922024, grad=0), Value(data=-0.3984540284725958, grad=0), Value(data=-0.36951529156971397, grad=0), Value(data=-0.4094919078854563, grad=0), Value(data=-0.34457105994113824, grad=0), Value(data=0.1713997318099865, grad=0), Value(data=0.5363618435445934, grad=0), Value(data=0.5290251949372154, grad=0)]\n",
      "[Value(data=-0.025766772598165885, grad=0), Value(data=-0.415140955489184, grad=0), Value(data=0.22275505231922024, grad=0), Value(data=-0.3984540284725958, grad=0), Value(data=-0.36951529156971397, grad=0), Value(data=-0.4094919078854563, grad=0), Value(data=-0.34457105994113824, grad=0), Value(data=0.1713997318099865, grad=0), Value(data=0.5363618435445934, grad=0), Value(data=0.5290251949372154, grad=0)]\n",
      "step 2 loss 0.7822986216763186, accuracy 70.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.8180042388054896, grad=0), Value(data=-0.5621940837079877, grad=0), Value(data=1.5658874865552292, grad=0), Value(data=-0.525814254217112, grad=0), Value(data=-0.13213758450928761, grad=0), Value(data=-0.5804675084806024, grad=0), Value(data=0.3057147750188559, grad=0), Value(data=1.7409356602126733, grad=0), Value(data=2.2187577497556226, grad=0), Value(data=2.0234740583247177, grad=0)]\n",
      "[Value(data=0.8180042388054896, grad=0), Value(data=-0.5621940837079877, grad=0), Value(data=1.5658874865552292, grad=0), Value(data=-0.525814254217112, grad=0), Value(data=-0.13213758450928761, grad=0), Value(data=-0.5804675084806024, grad=0), Value(data=0.3057147750188559, grad=0), Value(data=1.7409356602126733, grad=0), Value(data=2.2187577497556226, grad=0), Value(data=2.0234740583247177, grad=0)]\n",
      "step 3 loss 0.6528280301757685, accuracy 70.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.27723765616111296, grad=0), Value(data=-1.1357362196839245, grad=0), Value(data=0.6616182038387046, grad=0), Value(data=-1.0488129546025198, grad=0), Value(data=-0.855254073089005, grad=0), Value(data=-1.216867094435683, grad=0), Value(data=-0.7898970310958792, grad=0), Value(data=0.4483355701177385, grad=0), Value(data=1.1051810830883617, grad=0), Value(data=1.0843919737890046, grad=0)]\n",
      "[Value(data=0.27723765616111296, grad=0), Value(data=-1.1357362196839245, grad=0), Value(data=0.6616182038387046, grad=0), Value(data=-1.0488129546025198, grad=0), Value(data=-0.855254073089005, grad=0), Value(data=-1.216867094435683, grad=0), Value(data=-0.7898970310958792, grad=0), Value(data=0.4483355701177385, grad=0), Value(data=1.1051810830883617, grad=0), Value(data=1.0843919737890046, grad=0)]\n",
      "step 4 loss 0.5012518512699118, accuracy 80.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.7242560114880492, grad=0), Value(data=-1.0011293177263247, grad=0), Value(data=1.1328066713222702, grad=0), Value(data=-0.898154194999228, grad=0), Value(data=-0.23742400970852556, grad=0), Value(data=-1.0636928116528401, grad=0), Value(data=-0.0939074098133954, grad=0), Value(data=1.03447512166074, grad=0), Value(data=1.624615056134728, grad=0), Value(data=1.59841970444935, grad=0)]\n",
      "[Value(data=0.7242560114880492, grad=0), Value(data=-1.0011293177263247, grad=0), Value(data=1.1328066713222702, grad=0), Value(data=-0.898154194999228, grad=0), Value(data=-0.23742400970852556, grad=0), Value(data=-1.0636928116528401, grad=0), Value(data=-0.0939074098133954, grad=0), Value(data=1.03447512166074, grad=0), Value(data=1.624615056134728, grad=0), Value(data=1.59841970444935, grad=0)]\n",
      "step 5 loss 0.46653002676284644, accuracy 80.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.454926375950231, grad=0), Value(data=-1.2218371579230773, grad=0), Value(data=0.6365306493655774, grad=0), Value(data=-1.0474243389667162, grad=0), Value(data=-0.6946453478359959, grad=0), Value(data=-1.3160793479459756, grad=0), Value(data=-0.8115230545494657, grad=0), Value(data=0.3092819371183546, grad=0), Value(data=1.022019202024141, grad=0), Value(data=1.1097433863138368, grad=0)]\n",
      "[Value(data=0.454926375950231, grad=0), Value(data=-1.2218371579230773, grad=0), Value(data=0.6365306493655774, grad=0), Value(data=-1.0474243389667162, grad=0), Value(data=-0.6946453478359959, grad=0), Value(data=-1.3160793479459756, grad=0), Value(data=-0.8115230545494657, grad=0), Value(data=0.3092819371183546, grad=0), Value(data=1.022019202024141, grad=0), Value(data=1.1097433863138368, grad=0)]\n",
      "step 6 loss 0.47668569686057627, accuracy 80.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=1.1806045924186046, grad=0), Value(data=-1.0516003390835247, grad=0), Value(data=1.6356295901812354, grad=0), Value(data=-0.6505937783323396, grad=0), Value(data=0.2587675924449191, grad=0), Value(data=-1.177068521042069, grad=0), Value(data=0.3497954576810006, grad=0), Value(data=1.4389315106796308, grad=0), Value(data=2.1526833563781347, grad=0), Value(data=2.1052275283481694, grad=0)]\n",
      "[Value(data=1.1806045924186046, grad=0), Value(data=-1.0516003390835247, grad=0), Value(data=1.6356295901812354, grad=0), Value(data=-0.6505937783323396, grad=0), Value(data=0.2587675924449191, grad=0), Value(data=-1.177068521042069, grad=0), Value(data=0.3497954576810006, grad=0), Value(data=1.4389315106796308, grad=0), Value(data=2.1526833563781347, grad=0), Value(data=2.1052275283481694, grad=0)]\n",
      "step 7 loss 0.5088043782481894, accuracy 80.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=0.07158212508878076, grad=0), Value(data=-1.4620064159967676, grad=0), Value(data=0.2975386632253437, grad=0), Value(data=-1.3172105764205422, grad=0), Value(data=-1.0684402692390838, grad=0), Value(data=-1.6087690726523463, grad=0), Value(data=-1.0860445699375618, grad=0), Value(data=0.005905120045636009, grad=0), Value(data=0.61302875838136, grad=0), Value(data=0.6370810912268723, grad=0)]\n",
      "[Value(data=0.07158212508878076, grad=0), Value(data=-1.4620064159967676, grad=0), Value(data=0.2975386632253437, grad=0), Value(data=-1.3172105764205422, grad=0), Value(data=-1.0684402692390838, grad=0), Value(data=-1.6087690726523463, grad=0), Value(data=-1.0860445699375618, grad=0), Value(data=0.005905120045636009, grad=0), Value(data=0.61302875838136, grad=0), Value(data=0.6370810912268723, grad=0)]\n",
      "step 8 loss 0.6049732879194856, accuracy 80.0%\n",
      "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)], Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)], Layer of [LinearNeuron(4)]]\n",
      "[[Value(data=0.23716814800105823, grad=0), Value(data=-0.1733850803423769, grad=0)], [Value(data=-0.5522231840196069, grad=0), Value(data=0.5700331253604513, grad=0)], [Value(data=1.1425291398662902, grad=0), Value(data=-0.027946390980293462, grad=0)], [Value(data=-1.0559627906760132, grad=0), Value(data=0.11863833674456072, grad=0)], [Value(data=0.16985189051376626, grad=0), Value(data=0.3308779842359495, grad=0)], [Value(data=-0.069952284423216, grad=0), Value(data=1.0582962841937447, grad=0)], [Value(data=0.8049290441685284, grad=0), Value(data=0.5853695706393609, grad=0)], [Value(data=1.8670604551568166, grad=0), Value(data=0.49985452577335704, grad=0)], [Value(data=1.575641512808095, grad=0), Value(data=-0.24506795552830413, grad=0)], [Value(data=1.1265210647376644, grad=0), Value(data=-0.4879332255931098, grad=0)]]\n",
      "[Value(data=2.0372092685799625, grad=0), Value(data=-0.8217486500311544, grad=0), Value(data=2.882105826562264, grad=0), Value(data=-0.7723945865695161, grad=0), Value(data=1.022469372484465, grad=0), Value(data=-0.8404292590500896, grad=0), Value(data=1.44648332942647, grad=0), Value(data=2.9805610869321675, grad=0), Value(data=3.6888629321936817, grad=0), Value(data=3.5094526685706784, grad=0)]\n",
      "[Value(data=2.0372092685799625, grad=0), Value(data=-0.8217486500311544, grad=0), Value(data=2.882105826562264, grad=0), Value(data=-0.7723945865695161, grad=0), Value(data=1.022469372484465, grad=0), Value(data=-0.8404292590500896, grad=0), Value(data=1.44648332942647, grad=0), Value(data=2.9805610869321675, grad=0), Value(data=3.6888629321936817, grad=0), Value(data=3.5094526685706784, grad=0)]\n",
      "step 9 loss 0.6907075935214477, accuracy 80.0%\n"
     ]
    }
   ],
   "source": [
    "# optimization\n",
    "for k in range(10):\n",
    "    \n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    \n",
    "    #draw_dot(total_loss)\n",
    "\n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "    \n",
    "    # update (sgd)\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "    \n",
    "    if k % 1 == 0:\n",
    "        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.48793322559311, 2.01206677440689)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGhCAYAAACphlRxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApVElEQVR4nO3de3SUdZ7n8c9TuVQSSFUIuUuA4A0VDMjNoKPQpk2j63Z2e1y07UU9NrYcUOmw6xDHhdHTPTmn1dFWGRHdFnFktS+CtjpMIwqMGrUB04ottFw0IVCBNFBFQqhc6tk/IiVpck+eeupJvV/n1NE8+T3J11NI3nkuVYZpmqYAAAAcwmX3AAAAAH1BvAAAAEchXgAAgKMQLwAAwFGIFwAA4CjECwAAcBTiBQAAOArxAgAAHIV4AQAAjkK8AAAAR7E0XioqKjRt2jSlpqYqKytLpaWl2r17d4/7/eY3v9H48eOVlJSkiRMn6q233rJyTAAA4CCWxsuWLVu0cOFCffjhh9q4caNaWlp07bXXqrGxsct9PvjgA918882644479Mknn6i0tFSlpaXauXOnlaMCAACHMCL5xoxHjhxRVlaWtmzZoquuuqrTNXPnzlVjY6PeeOON8LbLL79ckyZN0sqVK3v8HqFQSAcPHlRqaqoMwxi02QEAgHVM09SJEyeUl5cnl6v7YyvxEZpJkuT3+yVJ6enpXa6prKxUWVlZh20lJSVav359p+uDwaCCwWD449raWl188cUDHxYAAERcTU2NRo0a1e2aiMVLKBTS4sWLdcUVV2jChAldrvP5fMrOzu6wLTs7Wz6fr9P1FRUVevDBB8/avv+XP1FqsntgQwMAgIg40RRUwb3PKDU1tce1EYuXhQsXaufOnXrvvfcG9euWl5d3OFITCASUn5+v1GS3PCnECwAATtKbSz4iEi+LFi3SG2+8oa1bt/Z4KCgnJ0d1dXUdttXV1SknJ6fT9W63W243kQIAQKyw9G4j0zS1aNEirVu3Tu+8844KCgp63KeoqEibNm3qsG3jxo0qKiqyakwAAOAglh55WbhwodauXavXXntNqamp4etWvF6vkpOTJUnz5s3TOeeco4qKCknSvffeq6uvvlqPPvqorr/+er388svatm2bVq1aZeWoAADAISw98vL000/L7/dr1qxZys3NDT9eeeWV8Jrq6modOnQo/PHMmTO1du1arVq1SoWFhfrtb3+r9evXd3uRLwAAiB0RfZ2XSAgEAvJ6vapfdQ8X7AIA4BCBk0Fl3PmE/H6/PB5Pt2t5byMAAOAoxAsAAHAU4gUAADgK8QIAAByFeAEAAI5CvAAAAEchXgAAgKMQLwAAwFGIFwAA4CjECwAAcBTiBQAAOArxAgAAHIV4AQAAjkK8AAAARyFeAACAoxAvAADAUYgXAADgKMQLAABwFOIFAAA4CvECAAAchXgBAACOQrwAAABHIV4AAICjEC8AAMBRiBcAAOAoxAsAAHAU4gUAADgK8QIAAByFeAEAAI5CvAAAAEchXgAAgKMQLwAAwFGIFwAA4CjECwAAcBTiBQAAOArxAgAAHIV4AQAAjkK8AAAARyFeAACAoxAvAADAUYgXAADgKMQLAABwFEvjZevWrbrhhhuUl5cnwzC0fv36btdv3rxZhmGc9fD5fFaOCQAAHMTSeGlsbFRhYaFWrFjRp/12796tQ4cOhR9ZWVkWTQgAAJwm3sovPmfOHM2ZM6fP+2VlZSktLW3wBwIAAI4Xlde8TJo0Sbm5ufrud7+r999/v9u1wWBQgUCgwwMAAAxdURUvubm5WrlypX73u9/pd7/7nfLz8zVr1izt2LGjy30qKirk9XrDj/z8/AhODAAAIs0wTdOMyDcyDK1bt06lpaV92u/qq6/W6NGj9eKLL3b6+WAwqGAwGP44EAgoPz9f9avukSfFPZCRAQBAhAROBpVx5xPy+/3yeDzdrrX0mpfBMH36dL333ntdft7tdsvtJlIAAIgVUXXaqDNVVVXKzc21ewwAABAlLD3y0tDQoD179oQ/3r9/v6qqqpSenq7Ro0ervLxctbW1WrNmjSTp8ccfV0FBgS655BKdOnVKzz33nN555x394Q9/sHJMAADgIJbGy7Zt2zR79uzwx2VlZZKkW2+9VatXr9ahQ4dUXV0d/nxzc7OWLFmi2tpapaSk6NJLL9Xbb7/d4WsAAIDYFrELdiMlEAjI6/VywS4AAA7Slwt2o/6aFwAAgDMRLwAAwFGIFwAA4CjECwAAcBTiBQAAOArxAgAAHIV4AQAAjkK8AAAARyFeAACAoxAvAADAUYgXAADgKMQLAABwFOIFAAA4CvECAAAchXgBAACOQrwAAABHIV4AAICjEC8AAMBRiBcAAOAoxAsAAHAU4gUAADgK8QIAAByFeAEAAI5CvAAAAEchXgAAgKMQLwAAwFGIFwAA4CjECwAAcBTiBQAAOArxAgAAHIV4AQAAjkK8AAAARyFeAACAoxAvAADAUeLtHgCA/U7UBbVnS71O+E4pLtGl/KlpGjU5Ta44w+7RAOAsxAsQw0zT1J9+e1A7X/fJcElmSDJc0v73jyo1263v3He+UrPcdo8JAB1w2giIYbs2HNbO132S2sPlzH82HAnq7Yq/qDUYsmk6AOgc8QLEqLaWkD577VCXnzdDUmN9s76qPBrBqQCgZ8QLEKPqdjWoubGt+0WGtP8D4gVAdCFegBjV3NDa8yJTCvZmHQBEEPECxKhhIxN7XGO4pOGZPa8DgEgiXoAYlXH+MA3v4U4iMySdd3VGhCYCgN6xNF62bt2qG264QXl5eTIMQ+vXr+9xn82bN+uyyy6T2+3Weeedp9WrV1s5IhCzDMPQ1FtGdfN5Kfui4cqb5I3gVADQM0vjpbGxUYWFhVqxYkWv1u/fv1/XX3+9Zs+eraqqKi1evFg//vGP9R//8R9WjgnErFGXpemqe8bJndr+kk+GS5LR/hg9Y4RmlZ0nl4sXqgMQXSx9kbo5c+Zozpw5vV6/cuVKFRQU6NFHH5UkXXTRRXrvvff02GOPqaSkxKoxgZg2etoIjZqcpgNVx3XCF1S826VzJns1PIMXpwMQnaLqFXYrKytVXFzcYVtJSYkWL17c5T7BYFDBYDD8cSAQsGo8YMhyxRsaPXWE3WMAQK9E1QW7Pp9P2dnZHbZlZ2crEAioqamp030qKirk9XrDj/z8/EiMCgAAbBJV8dIf5eXl8vv94UdNTY3dIwEAAAtF1WmjnJwc1dXVddhWV1cnj8ej5OTkTvdxu91yuzk3DwBArIiqIy9FRUXatGlTh20bN25UUVGRTRMBAIBoY2m8NDQ0qKqqSlVVVZLab4WuqqpSdXW1pPZTPvPmzQuvv+uuu7Rv3z7dd9992rVrl/71X/9Vv/71r/XTn/7UyjEBAICDWBov27Zt0+TJkzV58mRJUllZmSZPnqxly5ZJkg4dOhQOGUkqKCjQm2++qY0bN6qwsFCPPvqonnvuOW6TBgAAYYZpmqbdQwymQCAgr9er+lX3yJPCtTAAADhB4GRQGXc+Ib/fL4/H0+3aqLrmBQAAoCfECwAAcBTiBQAAOArxAgAAHIV4AQAAtnu54LxeryVeAACArV4cd0Gf1hMvAADANqfDxRiR1+t9iBcAAGCLcLikj+rTfsQLAACIuP6Gi0S8AACACBtIuEjECwAAiKCBhotEvAAAgAgZjHCRiBcAABBBAw0XiXgBAAAR8OK4CwYlXCTiBQAAWGwww0UiXgAAgIUGO1wk4gUAAFjEinCRiBcAAGABq8JFIl4AAMAgszJcJOIFAAAMIqvDRSJeAADAIIlEuEjECwAAGASRCheJeAEAAAMUyXCRiBcAADAAkQ4XiXgBAAD9ZEe4SMQLAADoB7vCRSJeAABAH9kZLhLxAgAA+sDucJGIFwAA0EvREC4S8QIAAHrhxXEX2D1CWLzdAwAAgP6JdFBEw1EXiXgBgIg6daJVe7fWy/fnEzLbTGWcO0znzc7Q8Ay33aPBYaLlFI4diBdggJobW9XSFJLbE6/4RM7EomsHP/Vryy/3qq3FlMz2bXVfnNDO3/s0bV6+LizOsndAOEYsh4tEvAD9VvfFCX32+iH5dp6QJLniDRVcka6J/zVXw7P4LRodHa9t0ubH9irU9m24SJIZav/nH1+o0bCRiRo1Oc2W+eAcsR4uEhfsAv2y/4Oj2ljxF9X9+UR4W6jV1L7//Kve+j9fyF/bZON0iEa7NtTJDHUMlw4MaedrvojOBOchXNoRL0AfnfK3qHLVV5L57W/Np5khqeVUm957er8tsyF6ff3hsbP+vHRgSvV7G3XyWHPEZoKzEC7fIl6APtqzpV6hUFe/PrcHzLGvm1S/rzGCUyHatQS7K5cz1jX1bh1iC+HSEfEC9FH93sauD/2fZkj1e4gXfGvYyMQe17jiDCWPSIjANHASwuVsxAvQR4Zh9HKdxYPAUS64JlPq5s+E4ZLGzBihxOS4yA2FqBdNLwwXTYgXoI+yxg/v9oeQJMmUssanRmQeOMP538lUarZbRid/6xouKSEpTpf+97zID4aodTpcOOpyNuIF6KNxfzdScQmuLgPGcElZFwzXiPzkyA6GqJaYEqeSBy5U3kTPWZ8bMSZF1y67UKnZ3GIfzU4E4/TvuzL05Htj9NT7o7Vhd4ZOBK05Uka4dC8ir/OyYsUKPfzww/L5fCosLNSTTz6p6dOnd7p29erVuv322ztsc7vdOnXqVCRGBXrkHhavq+4Zpy2P7ZVpmh3uIDFcUpI3QVcsKLBvQEStJG+CZv+v83WiLqi6Xe2vsDty3DClj02xezT0YPsBj579KF9tISN8ydufDnr02s5szb+8RpedExi070W49MzyIy+vvPKKysrKtHz5cu3YsUOFhYUqKSnR4cOHu9zH4/Ho0KFD4cfXX39t9ZhAn5xT6NWch8ZrbFG6XPHth2Dcw+N0yX/J0fU/u0jDMnq+OBOxKzXbrfOuztD538kkXBxg71+T9cyHo9UaMmTKkL55mDLUEjK0snK09h8dnCOthEvvWH7k5V/+5V80f/788NGUlStX6s0339SvfvUrLV26tNN9DMNQTk6O1aMBAzJidIquuKtAM38yVqFWs/1UEoAh5993ZX7zb52dKzYkmdqwK0MLZtYM6PsQLr1n6d+2zc3N2r59u4qLi7/9hi6XiouLVVlZ2eV+DQ0NGjNmjPLz8/X9739fn3/+eZdrg8GgAoFAhwcQSYZhEC7AENXcZuhPBz0KmV1fpR8yDX1y0KvWUP9vMSRc+sbSv3Hr6+vV1tam7OzsDtuzs7Pl83X+MtgXXnihfvWrX+m1117Tv/3bvykUCmnmzJk6cOBAp+srKirk9XrDj/z8/EH/7wAAxKZgq+ubU0XdC5mGmlv7Fy+ES99F3a+LRUVFmjdvniZNmqSrr75ar776qjIzM/XMM890ur68vFx+vz/8qKkZ2GE7AABOS0lokzuurcd1SfFtSkro+6sjEy79Y+k1LxkZGYqLi1NdXV2H7XV1db2+piUhIUGTJ0/Wnj17Ov282+2W283thQCAwRfnkq4oOKbNe0d2eerIZZj6u4JjcvXxwAvh0n+WHnlJTEzUlClTtGnTpvC2UCikTZs2qaioqFdfo62tTZ999plyc3OtGhMAgC7NGX9EwxLb5DLOfl8Ql2FqeGKrSi480qevSbgMjOWnjcrKyvTss8/qhRde0BdffKEFCxaosbExfPfRvHnzVF5eHl7/0EMP6Q9/+IP27dunHTt26Ec/+pG+/vpr/fjHP7Z6VAAAzjIiuVVLv7NXo9OaJJ2+Sbo9ZMaOOKny7+xVWnJrr78e4TJwlt8qPXfuXB05ckTLli2Tz+fTpEmTtGHDhvBFvNXV1XK5vm2oY8eOaf78+fL5fBoxYoSmTJmiDz74QBdffLHVowIA0Kns4c16oHivvj6WpD31w2QY0nkZjRqd1rcXUCVcBodhmmZP74/rKIFAQF6vV/Wr7pEnhWthAADRgXDpXlNDoxZO/Xv5/X55PGe/jcaZou5uIwAAhhrCZXARLwAAWIhwGXzECwAAFiFcrEG8AABgAcLFOsQLAACDjHCxluW3SgMA0J3TP+iHGsLFOsQLAMuFTOmzQ6navDddtf4kJcaHdNk5Ac0696jSU1rsHg824ggF+oN4AWCp1pC06sN87ahNk8sww+8Ps2G3Wxu/zNCiK77WJdkNNk8JOxAu6C+ueQFgqdc/z9YntV5J6vDGdiHTUGuboafeH6NjTfweFWsIFwwE8QLAMsFWQ+/sGSlTnb/drilDrSFDW/elR3gy2IlwwUARLwAss/evKTrVGtftGtM0tOOAN0ITwW6ECwYD8QLAMs1tvfsrprmt8yMzGFoIFwwW4gWAZfI8wR7XuAxTo/r4zrxwHsIFg4l4AWCZrOHNGp/ZIJfR9ZvXh0xDs849GsGpEGmECwYb8QLAUj+87KAS40JdBIypojHHdHEWt0oPVYQLrEC8ALBUnieo+6/Zq/GZHQMlJaFVpZfU6fZpB2RwycuQRLjAKry4AgDL5XmCKrv6K9U3Jsh3wq3EuJAK0puUENf16SQ4G+ECKxEvACImY1iLMobxdgBDHeECq3HaCAAwaAgXRALxAgAYFIQLIoV4AQAMGOGCSCJeAAADQrgg0ogXAEC/ES6wA/ECAOgXwgV2IV4AAH1GuMBOxAsAoE8IF9iNeAEA9BrhgmhAvAAAeoVwQbTg7QEQMaGQqUOfBeQ/eErxiS6dU+jVsIxEu8cC0AuEC6IJ8YKIOPipX5XPfa2mYy0yDMk0JRnS6OlpKrpjrBKS4+weEUAXCBdEG04bwXK+zwN699E9ajre/oZ85uk3Ejalmj8e1zuPfKlQK+8uDEQjwgXRiCMvsJRpmtr20oH2YOmkT8yQdOQvjarZflxjZoyI+HyAE50OikghXBBtiBdY6nh1k47XNHW7xnBJX24+QrwAvcCREIDTRrBYw1+be1xjhqSGw8EITAM4G+ECtCNeYKnElN5diJs4jIOAQHcIF+BbxAsslXn+cCV5ewgTQxp3RXpkBgIciHABOiJeYClXnKGJpbldft5wSUmeeI27cmQEpwKcg3ABzka8wHIXXJMZDhjjmz9xhtH+z+S0BBWXX8BpI6AThAvQOX5iwHKGYajwB3kad+VI7dl8RP6DpxSX4NKoy9I0elqa4hJoaOBvES5A14gXRExqtluT5/IXMdATwgXoHr/yAkAUIVyAnhEvABAlCBegdyISLytWrNDYsWOVlJSkGTNm6OOPP+52/W9+8xuNHz9eSUlJmjhxot56661IjAkAtiFcgN6zPF5eeeUVlZWVafny5dqxY4cKCwtVUlKiw4cPd7r+gw8+0M0336w77rhDn3zyiUpLS1VaWqqdO3daPSoA2IJwAfrGME3T0rfznTFjhqZNm6annnpKkhQKhZSfn6+7775bS5cuPWv93Llz1djYqDfeeCO87fLLL9ekSZO0cuXKHr9fIBCQ1+tV/ap75ElxD95/CABYwNZw2X9UenG79OYu6WSzdI5XuqlQurFQGpYY+XkQ05oaGrVw6t/L7/fL4/F0u9bSIy/Nzc3avn27iouLv/2GLpeKi4tVWVnZ6T6VlZUd1ktSSUlJl+uDwaACgUCHBwA4ga3h8v5XUulq6dd/kgKnpNaQVH1M+sVmae6L0rGTkZ8J6CVL46W+vl5tbW3Kzs7usD07O1s+n6/TfXw+X5/WV1RUyOv1hh/5+fmDMzwAWMjWcDneJN29Xmppk9rOOPhufvP46pj0jxsiPxfQS46/26i8vFx+vz/8qKmpsXskAOiW7de4rNspnWppD5XOtJnS5r3SgeORnAroNUtfpC4jI0NxcXGqq6vrsL2urk45OTmd7pOTk9On9W63W24317YAcAbbw0WSPvi663A5zZT0UY00Ki0CAwF9Y+mRl8TERE2ZMkWbNm0KbwuFQtq0aZOKioo63aeoqKjDeknauHFjl+sBwCmiIlwkqbWtd+vaQtbOAfST5aeNysrK9Oyzz+qFF17QF198oQULFqixsVG33367JGnevHkqLy8Pr7/33nu1YcMGPfroo9q1a5f+6Z/+Sdu2bdOiRYusHhUALBM14SJJE3KkOKPndZdk97wGsIHl7200d+5cHTlyRMuWLZPP59OkSZO0YcOG8EW51dXVcrm+baiZM2dq7dq1euCBB3T//ffr/PPP1/r16zVhwgSrRwUAS0RVuEjS3ELp/3bzYqFxhnRBpnRJ56frAbtZ/jovkcbrvACIJlEXLqe9uF3653cklyGFzvgxEGdIyQnSSz9sDxggQvryOi+8qzQAWCRqw0WS/ucUKSdVWvmh9OdvbpKIM6SSC6VFV0gF6fbOB3SDeAEAC0R1uJz23QvaHwcDUkNQyk6VvEl2TwX0iHgBgEHmiHA5U173h+iBaOP4F6kDgGjiuHABHIh4AYBBQrgAkcFpIwBD2umgiBTCBbAe8QLAdg3BOFV+nabaQJISXKYK8wK6OLtBrl68jlp3OBICDE3ECwBbbdk3Qv/vkzy1hQwZhilD0rt7Ryon9ZTuvfIrZQ5v6dfXJVyAoYtrXgDYZtsBj17cPkqtIUOmDIVMl9rM9r+WDje49fDmcWpq6ftfU4QLMLQRLwBsYZrSq5/lqP3ti88+PxQyDR1tStD7X43o09clXIChj3gBYIvq40k63OBWZ+Fypg/6EC+ECxAbiBcAtjgR7M0ld4YCp3p3aR7hAsQO4gWALdKSe74Q15CpESk9ryNcgNhCvACwxTmeoM7xNslQ129sb0q6suBot1+HcIlNpmmqrdmUGer6zw+GLm6VBmALw5BuvNSnX/7nWHV20a7LMJU1PKjLRx/v8msQLrHn1PE21Wxtkm/bKbUFTRnxUvYkt/KvStGwbH6kxQqOvACwzYScBv2kqFrJCSFJUpwRksto/026IP2k/ves/XLHd/6bNeESexrrWrXtl8dUW9mktmD7nwuzVarbEdT2J47p+L5mmydEpJCpAGw1dVRAl+Z+oe0HvDoYcCvBZerS3BMam97U5T6ES+wxTVOfvxhQ6ylTCv3N50Ltt97vXBNQ0T+OVFzCAF+aGVGPeAFgu8Q4U0VjjvdqLeESm47va9HJI21dLzCl1iZTh/8UVO7UpMgNBltw2giAYxAuscu/v0VGDz+xDFf7Ogx9xAsARyBcYlwvbioypfbzRxjyiBcAUY9wgWd0gsxQD4tCkmdMQkTmgb2IFwBRjXCBJI04P0FJI1zdvptEXKKUNYnrXWIB8QIgahEuOM1wGbrkRx7FJejsn1yu9utdLr7Fo3g3dxrFAuIFQFQiXPC3UkclaMo9I5Q92S0j7puNhpRxUaImL0zTyPFuW+dD5HCrNICoQ7igKymZ8brof3h0wX8z1XoypPhkl+ISOdoSa4gXAFGFcEFvxCUYivPG9bwQQxKnjQBEDcIFQG8QLwCiAuECoLeIFwC2I1wA9AXxAsBWhAuAviJeANiGcAHQH9xtBKCD00ERKYQLgL4iXgCEcSQEgBNw2giAJMIFgHMQLwAIFwCOQrwAMY5wAeA0xAsQwwgXAE5EvAAxinAB4FTECxCDCBcATsat0kCMIVwgSWbI1PF9LWr6a5vikwylX5Co+GR+n4UzEC9ADCFcIEn1fw7qy/UNCvpD4W2ueOmcK5NVcO0wueIMG6cDekZmAzGCcIHUHi471wQ6hIskhVqlms1N2v3bEzZNBvSepfFy9OhR3XLLLfJ4PEpLS9Mdd9yhhoaGbveZNWuWDMPo8LjrrrusHBMY8ggXSO2niv6yrkEyu15TtyOoQE1L5IYC+sHS00a33HKLDh06pI0bN6qlpUW333677rzzTq1du7bb/ebPn6+HHnoo/HFKSoqVYwJDGuGC047taVFzINT9Ipd06ONT8uQnRGYooB8si5cvvvhCGzZs0B//+EdNnTpVkvTkk0/quuuu0yOPPKK8vLwu901JSVFOTo5VowExg3DBmZqOtvW8KCQ11fdiHWAjy04bVVZWKi0tLRwuklRcXCyXy6WPPvqo231feuklZWRkaMKECSovL9fJkye7XBsMBhUIBDo8ABAuOFu8uxcX4hpSXBIX7CK6WXbkxefzKSsrq+M3i49Xenq6fD5fl/v98Ic/1JgxY5SXl6dPP/1U//AP/6Ddu3fr1Vdf7XR9RUWFHnzwwUGdHXA6wgWdSb8wUUacZHZ3YMWUsi51R2wmoD/6fORl6dKlZ11Q+7ePXbt29XugO++8UyUlJZo4caJuueUWrVmzRuvWrdPevXs7XV9eXi6/3x9+1NTU9Pt7A0MB4YKuJKS4lFeUJHV1YMUlJY1wKXMi8YLo1ucjL0uWLNFtt93W7Zpx48YpJydHhw8f7rC9tbVVR48e7dP1LDNmzJAk7dmzR+eee+5Zn3e73XK7+R8NkAgX9Ozc64ar+YSpI38Ktv/6GlJ7zJiS2+NS4fw0ueI5bYTo1ud4yczMVGZmZo/rioqKdPz4cW3fvl1TpkyRJL3zzjsKhULhIOmNqqoqSVJubm5fRwViCuGC3nDFGbr45lQFrkjWoY9Pqam+VfHJLmVe6lbmRLfiEggXRD/Lrnm56KKL9L3vfU/z58/XypUr1dLSokWLFummm24K32lUW1ura665RmvWrNH06dO1d+9erV27Vtddd51GjhypTz/9VD/96U911VVX6dJLL7VqVMDxCBf0hWEY8o5JkHcMt0PDmSx9kbqXXnpJ48eP1zXXXKPrrrtOV155pVatWhX+fEtLi3bv3h2+mygxMVFvv/22rr32Wo0fP15LlizRD37wA/3+97+3ckzA0QgXALHG0hepS09P7/YF6caOHSvT/PalHvPz87VlyxYrRwKGFMIFQCzivY0AhyNcAMQa4gVwqBfHXUC4AIhJxAvgQIQLgFhGvAAOQ7gAiHWWXrALxILTF81GCuECINYRL8AAcLcPAEQep42AfiJcAMAexAvQD4QLANiHeAH6iHABAHsRL0A/EC4AYB/iBegDblMGAPsRL0AvES4AEB2IF6AXCBcAiB7EC9ADwgUAogvxAnSDcAGA6EO8AF0gXAAgOhEvQCcIFwCIXsQL8DcIFwCIbsQLcAbCBQCiH/ECfINwAQBnIF4AES4A4CTEC2Ie4QIAzkK8IKYRLgDgPMQLYhbhAgDORLwgJhEuAOBcxAtiDuECAM5GvCCmvDjuArtHAAAMEPGCmHE6XDjqAgDORrwgJhAuADB0EC8Y8ggXABhaiBcMaYQLAAw98XYPgNgT6YtmCRcAGFqIF0QUtykDAAaK00aIGMIFADAYiBdEBOECABgsxAssR7gAAAYT8QJL8Yq2AIDBRrzAMtymDACwAvECSxAuAACrEC8YdIQLAMBKxAsGFeECALAa8YJBQ7gAACLBsnj5+c9/rpkzZyolJUVpaWm92sc0TS1btky5ublKTk5WcXGxvvzyS6tGxCAiXAAAkWJZvDQ3N+vGG2/UggULer3PL37xCz3xxBNauXKlPvroIw0bNkwlJSU6deqUVWNiEBAuAIBIsuy9jR588EFJ0urVq3u13jRNPf7443rggQf0/e9/X5K0Zs0aZWdna/369brpppusGhUDQLgAACItaq552b9/v3w+n4qLi8PbvF6vZsyYocrKyi73CwaDCgQCHR6IDMIFAGCHqIkXn88nScrOzu6wPTs7O/y5zlRUVMjr9YYf+fn5ls6JdoQLAMAufYqXpUuXyjCMbh+7du2yatZOlZeXy+/3hx81NTUR/f6xiHABANipT9e8LFmyRLfddlu3a8aNG9evQXJyciRJdXV1ys3NDW+vq6vTpEmTutzP7XbL7Xb363ui7wgXAIDd+hQvmZmZyszMtGSQgoIC5eTkaNOmTeFYCQQC+uijj/p0xxKsQ7gAAKKBZde8VFdXq6qqStXV1Wpra1NVVZWqqqrU0NAQXjN+/HitW7dOkmQYhhYvXqyf/exnev311/XZZ59p3rx5ysvLU2lpqVVjopcIFwBAtLDsVully5bphRdeCH88efJkSdK7776rWbNmSZJ2794tv98fXnPfffepsbFRd955p44fP64rr7xSGzZsUFJSklVjohcIFwBANDFM0zTtHmIwBQIBeb1e1a+6R54UroUZKMIFABAJTQ2NWjj17+X3++XxeLpdGzW3SiP6EC4AgGhEvKBThAsAIFoRLzgL4QIAiGbECzogXAAA0c6yu40weE4HRaQQLgCAaEa8RDmOhAAA0BGnjaIY4QIAwNmIlyhFuAAA0DniJQoRLgAAdI14iTKECwAA3SNeogjhAgBAz4iXKEG4AADQO8RLFCBcAADoPeLFZoQLAAB9Q7zYiHABAKDviBebEC4AAPQP8WIDwgUAgP4jXiKMcAEAYGCIlwgiXAAAGDjiJUIIFwAABgfxEgGECwAAg4d4sRjhAgDA4CJeLES4AAAw+IgXixAuAABYg3ixAOECAIB1iJdBRrgAAGAt4mUQES4AAFiPeBkkhAsAAJFBvAwCwgUAgMghXgaIcAEAILKIlwEgXAAAiLx4uwewyssF5yl5WLLl34dwAQAgsoZsvBgj8mQMH2b3GAAAYJBx2ggAADgK8QIAAByFeAEAAI5CvAAAAEchXgAAgKMQLwAAwFGIFwAA4CjECwAAcBTiBQAAOArxAgAAHGXIvT2AaZqSpKaGkzZPAgAAeuv0z+3TP8e7Y5i9WeUgBw4cUH5+vt1jAACAfqipqdGoUd2/6fGQi5dQKKSDBw8qNTVVhmGEtwcCAeXn56umpkYej8fGCdEVnqPoxvMT3Xh+oh/PUfdM09SJEyeUl5cnl6v7q1qG3Gkjl8vVbbF5PB7+0EQ5nqPoxvMT3Xh+oh/PUde8Xm+v1nHBLgAAcBTiBQAAOErMxIvb7dby5cvldrvtHgVd4DmKbjw/0Y3nJ/rxHA2eIXfBLgAAGNpi5sgLAAAYGogXAADgKMQLAABwFOIFAAA4CvECAAAcJebi5auvvtIdd9yhgoICJScn69xzz9Xy5cvV3Nxs92g4w89//nPNnDlTKSkpSktLs3scSFqxYoXGjh2rpKQkzZgxQx9//LHdI+EbW7du1Q033KC8vDwZhqH169fbPRLOUFFRoWnTpik1NVVZWVkqLS3V7t277R7L0WIuXnbt2qVQKKRnnnlGn3/+uR577DGtXLlS999/v92j4QzNzc268cYbtWDBArtHgaRXXnlFZWVlWr58uXbs2KHCwkKVlJTo8OHDdo8GSY2NjSosLNSKFSvsHgWd2LJlixYuXKgPP/xQGzduVEtLi6699lo1NjbaPZpj8Tovkh5++GE9/fTT2rdvn92j4G+sXr1aixcv1vHjx+0eJabNmDFD06ZN01NPPSWp/Q1Q8/Pzdffdd2vp0qU2T4czGYahdevWqbS01O5R0IUjR44oKytLW7Zs0VVXXWX3OI4Uc0deOuP3+5Wenm73GEBUam5u1vbt21VcXBze5nK5VFxcrMrKShsnA5zJ7/dLEj93BiDm42XPnj168skn9ZOf/MTuUYCoVF9fr7a2NmVnZ3fYnp2dLZ/PZ9NUgDOFQiEtXrxYV1xxhSZMmGD3OI41ZOJl6dKlMgyj28euXbs67FNbW6vvfe97uvHGGzV//nybJo8d/XmOAGAoWbhwoXbu3KmXX37Z7lEcLd7uAQbLkiVLdNttt3W7Zty4ceF/P3jwoGbPnq2ZM2dq1apVFk8Hqe/PEaJDRkaG4uLiVFdX12F7XV2dcnJybJoKcJ5FixbpjTfe0NatWzVq1Ci7x3G0IRMvmZmZyszM7NXa2tpazZ49W1OmTNHzzz8vl2vIHICKan15jhA9EhMTNWXKFG3atCl8EWgoFNKmTZu0aNEie4cDHMA0Td19991at26dNm/erIKCArtHcrwhEy+9VVtbq1mzZmnMmDF65JFHdOTIkfDn+C0yelRXV+vo0aOqrq5WW1ubqqqqJEnnnXeehg8fbu9wMaisrEy33nqrpk6dqunTp+vxxx9XY2Ojbr/9drtHg6SGhgbt2bMn/PH+/ftVVVWl9PR0jR492sbJILWfKlq7dq1ee+01paamhq8V83q9Sk5Otnk6hzJjzPPPP29K6vSB6HHrrbd2+hy9++67do8Ws5588klz9OjRZmJiojl9+nTzww8/tHskfOPdd9/t9P+XW2+91e7RYJpd/sx5/vnn7R7NsXidFwAA4Chc7AEAAByFeAEAAI5CvAAAAEchXgAAgKMQLwAAwFGIFwAA4CjECwAAcBTiBQAAOArxAgAAHIV4AQAAjkK8AAAAR/n/oz93RO4ry2IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize decision boundary\n",
    "\n",
    "h = 0.25\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
    "inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n",
    "scores = list(map(model, inputs))\n",
    "Z = np.array([s.data > 0 for s in scores])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
