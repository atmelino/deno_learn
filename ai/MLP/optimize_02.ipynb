{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimization manual steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pprint\n",
    "from mycrograd_debug.engine_debug import Value\n",
    "from mycrograd_debug.nn_debug import MLP\n",
    "from mycrograd_debug.drawviz_debug import (\n",
    "    draw_dot,\n",
    "    draw_nn,\n",
    "    print_all_values,\n",
    "    print_my_params,\n",
    ")\n",
    "from mycrograd_debug.util_debug import debugFunc\n",
    "\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "number_of_iterations = 10\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "global activation\n",
    "global loss\n",
    "global counter\n",
    "counter=0\n",
    "\n",
    "makeimg = False\n",
    "debug_steps = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron 1-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module nn MLP: structure [1, 2, 1]\n",
      "start\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.50   0.00\n",
      " v002  L1  N1  b   0.00   0.00\n",
      " v003  L1  N2 w1   0.50   0.00\n",
      " v004  L1  N2  b   0.00   0.00\n",
      " v005  L2  N1 w1   0.60   0.00\n",
      " v006  L2  N1 w2   1.20   0.00\n",
      " v007  L2  N1  b   0.00   0.00\n",
      "inputs\n",
      "[Value(name=v008,layernumber=,neuronnumber=,weightnumber=,type=i1,data=4, grad=0)]\n",
      "targets\n",
      "Value(name=v009,layernumber=,neuronnumber=,weightnumber=,type=t,data=1.2, grad=0)\n"
     ]
    }
   ],
   "source": [
    "# initialize a model\n",
    "nin = 1  # number of inputs\n",
    "nout = 1  # number of outputs\n",
    "Value.value_counter = 0\n",
    "model = MLP(nin, [2, nout], weightsinit=2, lastReLU=False, debug_bw=False)\n",
    "xinumbers = list(range(4, 4 + nin))\n",
    "xinput = [Value(x, type=\"i%s\" % index) for index, x in enumerate(xinumbers, start=1)]\n",
    "xtarget = Value(1.2, type=\"t\")  # desired targets\n",
    "debugFunc(model, {\"parameters\"}, message=\"start\", inputs=xinput, targets=xtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function single MLP\n",
    "def loss_single(activation, target):\n",
    "    total_loss = (activation - target)*(activation - target)\n",
    "    total_loss.type=\"l\"\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImage(filename):\n",
    "    # print(filename)\n",
    "    dot1=draw_dot(activation)\n",
    "    dot1.render(\"images/\"+filename , format=\"svg\", view=True)\n",
    "    dot2=draw_nn(xinput, model)\n",
    "    dot2.render(\"images/nn/\"+filename, format=\"svg\", view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act():\n",
    "    #### forward pass\n",
    "    global activation\n",
    "    global loss\n",
    "    activation = model(xinput)\n",
    "    loss = loss_single(activation, xtarget)\n",
    "    debugFunc(model, {\"parameters\"}, message=\"act\")\n",
    "\n",
    "\n",
    "def zeroGrad():\n",
    "    global activation\n",
    "    model.zero_grad()\n",
    "    for i in xinput:\n",
    "        i.grad = 0\n",
    "    debugFunc(model, {\"parameters\"}, message=\"zer\")\n",
    "\n",
    "\n",
    "def back():\n",
    "    #### backward pass\n",
    "    global activation\n",
    "    activation.backward()\n",
    "    debugFunc(model, {\"parameters\"}, message=\"bwd\")\n",
    "\n",
    "\n",
    "def upd():\n",
    "    #### update\n",
    "    global activation\n",
    "    for p in model.parameters():\n",
    "        p.data += -0.05 * p.grad\n",
    "    debugFunc(model, {\"parameters\"}, message=\"upd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optStep(filename=\"default\"):\n",
    "    global model\n",
    "    global counter\n",
    "    counter = counter + 1\n",
    "    act()\n",
    "    zeroGrad()\n",
    "    back()\n",
    "    upd()\n",
    "    print(f\"step %3d output %6.4f loss %6.4f\" % (counter, activation.data, loss.data))\n",
    "    dot = draw_nn(xinput, model)\n",
    "    dot.node(name=\"a\", label=\"clicked %3d\" % counter, shape=\"record\")\n",
    "    dot.render(\"static/\" + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt():\n",
    "    global loss\n",
    "\n",
    "    for k in range(number_of_iterations):\n",
    "        print(\"start step %d\" % k)\n",
    "\n",
    "        if debug_steps:\n",
    "            print(\"step %d loss calc\" % k)\n",
    "        act()\n",
    "        if makeimg:\n",
    "            makeImage(\"opt_01_step%d_1loss\" % k)\n",
    "\n",
    "        if debug_steps:\n",
    "            print(\"step %d zero grad\" % k)\n",
    "        zeroGrad()\n",
    "        if makeimg:\n",
    "            makeImage(\"opt_01_step%d_2zero\" % k)\n",
    "\n",
    "        if debug_steps:\n",
    "            print(\"step %d backward\" % k)\n",
    "        back()\n",
    "        if makeimg:\n",
    "            makeImage(\"opt_01_step%d_3back\" % k)\n",
    "\n",
    "        if debug_steps:\n",
    "            print(\"step %d update\" % k)\n",
    "        upd()\n",
    "        if makeimg:\n",
    "            makeImage(\"opt_01_step%d_3upda\" % k)\n",
    "\n",
    "        print(f\"step %3d output %6.4f loss %6.4f\" % (k, activation.data, loss.data))\n",
    "\n",
    "# opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.50   0.00\n",
      " v002  L1  N1  b   0.00   0.00\n",
      " v003  L1  N2 w1   0.50   0.00\n",
      " v004  L1  N2  b   0.00   0.00\n",
      " v005  L2  N1 w1   0.60   0.00\n",
      " v006  L2  N1 w2   1.20   0.00\n",
      " v007  L2  N1  b   0.00   0.00\n",
      "zer\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.50   0.00\n",
      " v002  L1  N1  b   0.00   0.00\n",
      " v003  L1  N2 w1   0.50   0.00\n",
      " v004  L1  N2  b   0.00   0.00\n",
      " v005  L2  N1 w1   0.60   0.00\n",
      " v006  L2  N1 w2   1.20   0.00\n",
      " v007  L2  N1  b   0.00   0.00\n",
      "bwd\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.50   2.40\n",
      " v002  L1  N1  b   0.00   0.60\n",
      " v003  L1  N2 w1   0.50   4.80\n",
      " v004  L1  N2  b   0.00   1.20\n",
      " v005  L2  N1 w1   0.60   2.00\n",
      " v006  L2  N1 w2   1.20   2.00\n",
      " v007  L2  N1  b   0.00   1.00\n",
      "upd\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.38   2.40\n",
      " v002  L1  N1  b  -0.03   0.60\n",
      " v003  L1  N2 w1   0.26   4.80\n",
      " v004  L1  N2  b  -0.06   1.20\n",
      " v005  L2  N1 w1   0.50   2.00\n",
      " v006  L2  N1 w2   1.10   2.00\n",
      " v007  L2  N1  b  -0.05   1.00\n",
      "step   1 output 3.6000 loss 5.7600\n"
     ]
    }
   ],
   "source": [
    "optStep(filename=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.38   2.40\n",
      " v002  L1  N1  b  -0.03   0.60\n",
      " v003  L1  N2 w1   0.26   4.80\n",
      " v004  L1  N2  b  -0.06   1.20\n",
      " v005  L2  N1 w1   0.50   2.00\n",
      " v006  L2  N1 w2   1.10   2.00\n",
      " v007  L2  N1  b  -0.05   1.00\n",
      "zer\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.38   0.00\n",
      " v002  L1  N1  b  -0.03   0.00\n",
      " v003  L1  N2 w1   0.26   0.00\n",
      " v004  L1  N2  b  -0.06   0.00\n",
      " v005  L2  N1 w1   0.50   0.00\n",
      " v006  L2  N1 w2   1.10   0.00\n",
      " v007  L2  N1  b  -0.05   0.00\n",
      "bwd\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.38   2.00\n",
      " v002  L1  N1  b  -0.03   0.50\n",
      " v003  L1  N2 w1   0.26   4.40\n",
      " v004  L1  N2  b  -0.06   1.10\n",
      " v005  L2  N1 w1   0.50   1.49\n",
      " v006  L2  N1 w2   1.10   0.98\n",
      " v007  L2  N1  b  -0.05   1.00\n",
      "upd\n",
      "parameters\n",
      " name lay neu ty   data   grad\n",
      " v001  L1  N1 w1   0.28   2.00\n",
      " v002  L1  N1  b  -0.06   0.50\n",
      " v003  L1  N2 w1   0.04   4.40\n",
      " v004  L1  N2  b  -0.12   1.10\n",
      " v005  L2  N1 w1   0.43   1.49\n",
      " v006  L2  N1 w2   1.05   0.98\n",
      " v007  L2  N1  b  -0.10   1.00\n",
      "step   2 output 1.7730 loss 0.3283\n"
     ]
    }
   ],
   "source": [
    "optStep(filename=\"default\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
