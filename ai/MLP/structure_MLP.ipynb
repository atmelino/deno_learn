{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  print out structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from mycrograd_debug.engine_debug import Value\n",
    "from mycrograd_debug.nn_debug import Neuron, Layer, MLP, MLP_linear\n",
    "from mycrograd_debug.drawviz_debug import draw_dot\n",
    "\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron 1-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model \n",
    "nin=1  #number of inputs\n",
    "nout=1  #number of outputs\n",
    "Value.value_counter=0\n",
    "\n",
    "# model = MLP_linear(nin, [2,  nout]) # 1-layer neural network\n",
    "model = MLP(nin, [2,  nout]) # 1-layer neural network\n",
    "xinumbers = list(range(1, nin+1))\n",
    "xinput = [Value(x,type='i') for x in xinumbers]\n",
    "print(\"inputs \", xinput)\n",
    "\n",
    "activation = model(xinput)\n",
    "activation.backward()\n",
    "\n",
    "print(\"number of Value objects created = \",Value.value_counter)\n",
    "\n",
    "draw_dot(activation, debug_print_01=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron 1-2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model \n",
    "nin=1  #number of inputs\n",
    "nout=2  #number of outputs\n",
    "Value.value_counter=0\n",
    "\n",
    "model = MLP_linear(nin, [2,  nout]) # 1-layer neural network\n",
    "xinumbers = list(range(1, nin+1))\n",
    "xinput = [Value(x,type='i') for x in xinumbers]\n",
    "print(\"inputs \", xinput)\n",
    "\n",
    "print(model(xinput))\n",
    "\n",
    "activation=[]\n",
    "activation= model(xinput)\n",
    "activation[0].backward()\n",
    "activation[1].backward()\n",
    "\n",
    "print(\"number of Value objects created = \",Value.value_counter)\n",
    "\n",
    "draw_dot(activation[0], debug_print_01=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(activation[1], debug_print_01=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron 3-4-4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function single MLP\n",
    "def loss_single(target,output):\n",
    "    total_loss = (output - target)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model \n",
    "nin=3  #number of inputs\n",
    "nout=1  #number of outputs\n",
    "Value.value_counter=0\n",
    "\n",
    "model = MLP_linear(nin, [4, 4, nout]) # 2-layer neural network\n",
    "xinumbers = list(range(1, nin+1))\n",
    "xinput = [Value(x,type='i') for x in xinumbers]\n",
    "print(\"inputs \", xinput)\n",
    "\n",
    "activation = model(xinput)\n",
    "\n",
    "#ys = [[1.0]]  \n",
    "xtarget=Value(1.2,type='t') # desired targets\n",
    "\n",
    "loss=loss_single(activation,xtarget)\n",
    "loss.backward()\n",
    "print(\"loss= \",loss)\n",
    "print(\"number of Value objects created = \",Value.value_counter)\n",
    "\n",
    "draw_dot(loss, debug_print_01=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 times Multi Layer Perceptron 3-4-4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function multiple MLP's\n",
    "def loss_mult(targets,outputs):\n",
    "    total_loss = sum((yout - ygt) ** 2 for ygt, yout in zip(outputs, targets))\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model\n",
    "nin = 3  # number of inputs\n",
    "nout = 1  # number of outputs\n",
    "\n",
    "Value.value_counter = 0\n",
    "\n",
    "model = MLP(nin, [4, 4, nout])  # 2-layer neural network\n",
    "xinumbers1 = np.array(list(range(1, nin * 4 + 1)))\n",
    "xinumbers = xinumbers1.reshape(nin, 4)\n",
    "print(xinumbers)\n",
    "\n",
    "xinput = [[Value(3) for x in range(4)] for y in range(3)]\n",
    "print(xinput)\n",
    "\n",
    "for i in range(len(xinumbers)):\n",
    "    for j in range(len(xinumbers[i])):\n",
    "        xinput[i][j].type = \"i\"\n",
    "        xinput[i][j].data = xinumbers[i][j]\n",
    "\n",
    "print(\"inputs \", xinput)\n",
    "print(\"input 0 \", xinput[0])\n",
    "\n",
    "activation = [model(x) for x in xinput]\n",
    "\n",
    "ys = [15.0, -16.0, -17.0, 18.0]  # desired targets\n",
    "xtarget = [Value(x, type=\"t\") for x in ys]\n",
    "print(\"xtarget= \", xtarget)\n",
    "loss = loss_mult(activation, xtarget)\n",
    "print(\"loss= \", loss)\n",
    "print(\"number of Value objects created = \", Value.value_counter)\n",
    "loss.backward()\n",
    "\n",
    "draw_dot(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
