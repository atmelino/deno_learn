{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MicroGrad demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mycrograd_debug.engine_debug import Value\n",
    "from mycrograd_debug.nn_debug import Neuron, Layer, MLP\n",
    "from mycrograd_debug.drawviz_debug import draw_dot,draw_nn,print_all_values\n",
    "import pprint\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "number_of_samples=4\n",
    "number_of_iterations=10\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "debug_values = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.02183808,  0.35430742],\n",
      "       [ 0.82773723,  0.0961832 ],\n",
      "       [-1.09199463, -0.10965849],\n",
      "       [ 2.1335573 ,  0.42420399]])\n",
      "array([1, 0, 0, 1])\n",
      "array([ 1, -1, -1,  1])\n"
     ]
    }
   ],
   "source": [
    "# make up a dataset\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "X, y = make_moons(n_samples=number_of_samples, noise=0.1)\n",
    "pp.pprint(X)\n",
    "pp.pprint(y)\n",
    "y = y*2 - 1 # make y be -1 or 1\n",
    "pp.pprint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module nn MLP: structure [2, 2, 1]\n",
      "[   [   Value(name=v010,layernumber=,neuronnumber=,weightnumber=,type=,data=0.0218380834585633, grad=0),\n",
      "        Value(name=v011,layernumber=,neuronnumber=,weightnumber=,type=,data=0.35430741854819914, grad=0)],\n",
      "    [   Value(name=v012,layernumber=,neuronnumber=,weightnumber=,type=,data=0.8277372309744037, grad=0),\n",
      "        Value(name=v013,layernumber=,neuronnumber=,weightnumber=,type=,data=0.09618319872606, grad=0)],\n",
      "    [   Value(name=v014,layernumber=,neuronnumber=,weightnumber=,type=,data=-1.0919946290642557, grad=0),\n",
      "        Value(name=v015,layernumber=,neuronnumber=,weightnumber=,type=,data=-0.1096584897551003, grad=0)],\n",
      "    [   Value(name=v016,layernumber=,neuronnumber=,weightnumber=,type=,data=2.133557297233384, grad=0),\n",
      "        Value(name=v017,layernumber=,neuronnumber=,weightnumber=,type=,data=0.42420399367691636, grad=0)]]\n"
     ]
    }
   ],
   "source": [
    "# initialize a model \n",
    "# model = MLP(2, [16, 16, 1]) # 2-layer neural network\n",
    "model = MLP(2, [2, 1], lastReLU=True, debug_bw=False) # 2-layer neural network\n",
    "# print(model)\n",
    "# pp.pprint(model.parameters())\n",
    "# pp.pprint(model.layers)\n",
    "\n",
    "Xb, yb = X, y\n",
    "inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "pp.pprint(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss():\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    pp.pprint(scores)\n",
    "\n",
    "    # svm \"max-margin\" loss\n",
    "    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "# total_loss, acc = loss()\n",
    "# print(total_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start step 0\n",
      "[   Value(name=v031,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.016436428967818627, grad=0),\n",
      "    Value(name=v045,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.1346183875256753, grad=0),\n",
      "    Value(name=v059,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.17786782634182813, grad=0),\n",
      "    Value(name=v073,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.3548313015504008, grad=0)]\n",
      "step 0 loss calc\n",
      "step 0 zero grad\n",
      "step 0 backward\n",
      "step 0 loss 1.0955140025642771, accuracy 50.0%\n",
      "start step 1\n",
      "[   Value(name=v136,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.05078620433112108, grad=0),\n",
      "    Value(name=v150,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.0, grad=0),\n",
      "    Value(name=v164,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.040733300229352204, grad=0),\n",
      "    Value(name=v178,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.0, grad=0)]\n",
      "step 1 loss calc\n",
      "step 1 zero grad\n",
      "step 1 backward\n",
      "step 1 loss 0.9975654522440869, accuracy 50.0%\n",
      "start step 2\n",
      "[   Value(name=v241,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.06772337770073267, grad=0),\n",
      "    Value(name=v255,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.05586429347276333, grad=0),\n",
      "    Value(name=v269,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.0, grad=0),\n",
      "    Value(name=v283,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.17719454983204455, grad=0)]\n",
      "step 2 loss calc\n",
      "step 2 zero grad\n",
      "step 2 backward\n",
      "step 2 loss 0.9528193873628602, accuracy 75.0%\n",
      "start step 3\n",
      "[   Value(name=v346,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.20246353839499295, grad=0),\n",
      "    Value(name=v360,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.2776797035792757, grad=0),\n",
      "    Value(name=v374,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.0, grad=0),\n",
      "    Value(name=v388,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.6087691029045825, grad=0)]\n",
      "step 3 loss calc\n",
      "step 3 zero grad\n",
      "step 3 backward\n",
      "step 3 loss 0.8667206480758144, accuracy 75.0%\n",
      "start step 4\n",
      "[   Value(name=v451,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.44107239746503046, grad=0),\n",
      "    Value(name=v465,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.6650355094174364, grad=0),\n",
      "    Value(name=v479,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.0, grad=0),\n",
      "    Value(name=v493,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=1.369142263434252, grad=0)]\n",
      "step 4 loss calc\n",
      "step 4 zero grad\n",
      "step 4 backward\n",
      "step 4 loss 0.8061639288411601, accuracy 75.0%\n",
      "start step 5\n",
      "[   Value(name=v556,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.18069786645549907, grad=0),\n",
      "    Value(name=v570,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.26799706931312817, grad=0),\n",
      "    Value(name=v584,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.241, grad=0),\n",
      "    Value(name=v598,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.7584782495469516, grad=0)]\n",
      "step 5 loss calc\n",
      "step 5 zero grad\n",
      "step 5 backward\n",
      "step 5 loss 0.7721160613286165, accuracy 75.0%\n",
      "start step 6\n",
      "[   Value(name=v661,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.5849220326516988, grad=0),\n",
      "    Value(name=v675,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.8862701412545311, grad=0),\n",
      "    Value(name=v689,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.24095396900000005, grad=0),\n",
      "    Value(name=v703,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=1.9459618963782748, grad=0)]\n",
      "step 6 loss calc\n",
      "step 6 zero grad\n",
      "step 6 backward\n",
      "step 6 loss 0.7653656370499874, accuracy 75.0%\n",
      "start step 7\n",
      "[   Value(name=v766,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.3162224957507478, grad=0),\n",
      "    Value(name=v780,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.4151337795396154, grad=0),\n",
      "    Value(name=v794,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.4643048874848373, grad=0),\n",
      "    Value(name=v808,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=1.1608192243412643, grad=0)]\n",
      "step 7 loss calc\n",
      "step 7 zero grad\n",
      "step 7 backward\n",
      "step 7 loss 0.6589121575654457, accuracy 75.0%\n",
      "start step 8\n",
      "[   Value(name=v871,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.13923464845793154, grad=0),\n",
      "    Value(name=v885,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.011407702690893973, grad=0),\n",
      "    Value(name=v899,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.7115689141785578, grad=0),\n",
      "    Value(name=v913,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.8295714564954292, grad=0)]\n",
      "step 8 loss calc\n",
      "step 8 zero grad\n",
      "step 8 backward\n",
      "step 8 loss 0.646956326666792, accuracy 75.0%\n",
      "start step 9\n",
      "[   Value(name=v976,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.4362974530204049, grad=0),\n",
      "    Value(name=v990,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=0.8756956127000861, grad=0),\n",
      "    Value(name=v1004,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=-0.7114368469880863, grad=0),\n",
      "    Value(name=v1018,layernumber=L2,neuronnumber=N1,weightnumber=,type=a,data=2.5892517563935322, grad=0)]\n",
      "step 9 loss calc\n",
      "step 9 zero grad\n",
      "step 9 backward\n",
      "step 9 loss 0.6824339496598467, accuracy 75.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# optimization\n",
    "makeimg=False\n",
    "for k in range(number_of_iterations):\n",
    "    print(\"start step %d\" %k)\n",
    "    # pp.pprint(model.parameters())\n",
    "\n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    print(\"step %d loss calc\" %k)\n",
    "    if debug_values:\n",
    "        print_all_values(total_loss)\n",
    "    if makeimg:\n",
    "        dot=draw_dot(total_loss)\n",
    "        dot.render(\"images/opt_01_step%d_1loss\" % k , format=\"svg\", view=True)\n",
    "\n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    print(\"step %d zero grad\" %k)\n",
    "    if debug_values:\n",
    "        print_all_values(total_loss)\n",
    "    if makeimg:\n",
    "        dot=draw_dot(total_loss)\n",
    "        dot.render(\"images/opt_01_step%d_2zero\" % k , format=\"svg\", view=True)\n",
    "\n",
    "    total_loss.backward()\n",
    "    print(\"step %d backward\" %k)\n",
    "    if debug_values:\n",
    "        print_all_values(total_loss)\n",
    "    if makeimg:\n",
    "        dot=draw_dot(total_loss)\n",
    "        dot.render(\"images/opt_01_step%d_3back\" % k , format=\"svg\", view=True)\n",
    "    \n",
    "    # update (sgd)\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "    \n",
    "    # if k % 1 == 0:\n",
    "    #     print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n",
    "    print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
