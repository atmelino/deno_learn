{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MicroGrad demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mycrograd_debug.engine_debug import Value\n",
    "from mycrograd_debug.nn_debug import Neuron, Layer, MLP\n",
    "from mycrograd_debug.drawviz_debug import draw_dot,draw_nn,print_all_values\n",
    "import pprint\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "number_of_samples=2\n",
    "number_of_iterations=2\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.8572558 ,  0.03006228],\n",
      "       [-0.05120403,  0.50473341]])\n",
      "array([0, 1])\n",
      "array([-1,  1])\n"
     ]
    }
   ],
   "source": [
    "# make up a dataset\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "X, y = make_moons(n_samples=number_of_samples, noise=0.1)\n",
    "pp.pprint(X)\n",
    "pp.pprint(y)\n",
    "y = y*2 - 1 # make y be -1 or 1\n",
    "pp.pprint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module nn MLP: structure [2, 2, 1]\n",
      "[   [   Value(name=v010,layernumber=,neuronnumber=,weightnumber=,type=,data=0.8572557995669348, grad=0),\n",
      "        Value(name=v011,layernumber=,neuronnumber=,weightnumber=,type=,data=0.03006227935826109, grad=0)],\n",
      "    [   Value(name=v012,layernumber=,neuronnumber=,weightnumber=,type=,data=-0.051204029028939925, grad=0),\n",
      "        Value(name=v013,layernumber=,neuronnumber=,weightnumber=,type=,data=0.5047334093296381, grad=0)]]\n",
      "[   [   Value(name=v010,layernumber=,neuronnumber=,weightnumber=,type=i,data=0.8572557995669348, grad=0),\n",
      "        Value(name=v011,layernumber=,neuronnumber=,weightnumber=,type=i,data=0.03006227935826109, grad=0)],\n",
      "    [   Value(name=v012,layernumber=,neuronnumber=,weightnumber=,type=i,data=-0.051204029028939925, grad=0),\n",
      "        Value(name=v013,layernumber=,neuronnumber=,weightnumber=,type=i,data=0.5047334093296381, grad=0)]]\n"
     ]
    }
   ],
   "source": [
    "# initialize a model \n",
    "# model = MLP(2, [16, 16, 1]) # 2-layer neural network\n",
    "model = MLP(2, [2, 1], debug_bw=False) # 2-layer neural network\n",
    "# print(model)\n",
    "# pp.pprint(model.parameters())\n",
    "Xb, yb = X, y\n",
    "inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "pp.pprint(inputs)\n",
    "for i in range(len(inputs)):\n",
    "    for j in range(len(inputs[i])):\n",
    "        inputs[i][j].type = \"i\"\n",
    "pp.pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss():\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    \n",
    "    # svm \"max-margin\" loss\n",
    "    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "# total_loss, acc = loss()\n",
    "# print(total_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start step 0\n",
      "step 0 loss calc\n",
      "name ty   data   grad\n",
      "v001 w1   0.24   0.00\n",
      "v002 w2   0.07   0.00\n",
      "v003  b   0.00   0.00\n",
      "v004 w1  -0.27   0.00\n",
      "v005 w2   0.17   0.00\n",
      "v006  b   0.00   0.00\n",
      "v007 w1  -0.67   0.00\n",
      "v008 w2   0.65   0.00\n",
      "v009  b   0.00   0.00\n",
      "v010  i   0.86   0.00\n",
      "v011  i   0.03   0.00\n",
      "v012  i  -0.05   0.00\n",
      "v013  i   0.50   0.00\n",
      "v014      0.20   0.00\n",
      "v015      0.20   0.00\n",
      "v016      0.00   0.00\n",
      "v017  a   0.20   0.00\n",
      "v018      0.20   0.00\n",
      "v019     -0.23   0.00\n",
      "v020     -0.23   0.00\n",
      "v021      0.01   0.00\n",
      "v022  a  -0.22   0.00\n",
      "v023      0.00   0.00\n",
      "v024     -0.14   0.00\n",
      "v025     -0.14   0.00\n",
      "v026      0.00   0.00\n",
      "v027  a  -0.14   0.00\n",
      "v028     -0.01   0.00\n",
      "v029     -0.01   0.00\n",
      "v030      0.03   0.00\n",
      "v031  a   0.02   0.00\n",
      "v032      0.02   0.00\n",
      "v033      0.01   0.00\n",
      "v034      0.01   0.00\n",
      "v035      0.09   0.00\n",
      "v036  a   0.10   0.00\n",
      "v037      0.10   0.00\n",
      "v038     -0.01   0.00\n",
      "v039     -0.01   0.00\n",
      "v040      0.07   0.00\n",
      "v041  a   0.05   0.00\n",
      "v042      1.00   0.00\n",
      "v043     -0.14   0.00\n",
      "v044      1.00   0.00\n",
      "v045      0.86   0.00\n",
      "v046      0.86   0.00\n",
      "v047     -1.00   0.00\n",
      "v048     -0.05   0.00\n",
      "v049      1.00   0.00\n",
      "v050      0.95   0.00\n",
      "v051      0.95   0.00\n",
      "v052      0.00   0.00\n",
      "v053      0.86   0.00\n",
      "v054      1.81   0.00\n",
      "v055      0.50   0.00\n",
      "v056      0.91   0.00\n",
      "v057      0.06   0.00\n",
      "v058      0.00   0.00\n",
      "v059      0.06   0.00\n",
      "v060      0.00   0.00\n",
      "v061      0.06   0.00\n",
      "v062      0.00   0.00\n",
      "v063      0.06   0.00\n",
      "v064      0.07   0.00\n",
      "v065      0.13   0.00\n",
      "v066      0.03   0.00\n",
      "v067      0.16   0.00\n",
      "v068      0.00   0.00\n",
      "v069      0.16   0.00\n",
      "v070      0.45   0.00\n",
      "v071      0.61   0.00\n",
      "v072      0.42   0.00\n",
      "v073      1.03   0.00\n",
      "v074      0.00   0.00\n",
      "v075      1.03   0.00\n",
      "v076      0.00   0.00\n",
      "v077      0.00   0.00\n",
      "v078      0.91   0.00\n",
      "step 0 zero grad\n",
      "name ty   data   grad\n",
      "v001 w1   0.24   0.00\n",
      "v002 w2   0.07   0.00\n",
      "v003  b   0.00   0.00\n",
      "v004 w1  -0.27   0.00\n",
      "v005 w2   0.17   0.00\n",
      "v006  b   0.00   0.00\n",
      "v007 w1  -0.67   0.00\n",
      "v008 w2   0.65   0.00\n",
      "v009  b   0.00   0.00\n",
      "v010  i   0.86   0.00\n",
      "v011  i   0.03   0.00\n",
      "v012  i  -0.05   0.00\n",
      "v013  i   0.50   0.00\n",
      "v014      0.20   0.00\n",
      "v015      0.20   0.00\n",
      "v016      0.00   0.00\n",
      "v017  a   0.20   0.00\n",
      "v018      0.20   0.00\n",
      "v019     -0.23   0.00\n",
      "v020     -0.23   0.00\n",
      "v021      0.01   0.00\n",
      "v022  a  -0.22   0.00\n",
      "v023      0.00   0.00\n",
      "v024     -0.14   0.00\n",
      "v025     -0.14   0.00\n",
      "v026      0.00   0.00\n",
      "v027  a  -0.14   0.00\n",
      "v028     -0.01   0.00\n",
      "v029     -0.01   0.00\n",
      "v030      0.03   0.00\n",
      "v031  a   0.02   0.00\n",
      "v032      0.02   0.00\n",
      "v033      0.01   0.00\n",
      "v034      0.01   0.00\n",
      "v035      0.09   0.00\n",
      "v036  a   0.10   0.00\n",
      "v037      0.10   0.00\n",
      "v038     -0.01   0.00\n",
      "v039     -0.01   0.00\n",
      "v040      0.07   0.00\n",
      "v041  a   0.05   0.00\n",
      "v042      1.00   0.00\n",
      "v043     -0.14   0.00\n",
      "v044      1.00   0.00\n",
      "v045      0.86   0.00\n",
      "v046      0.86   0.00\n",
      "v047     -1.00   0.00\n",
      "v048     -0.05   0.00\n",
      "v049      1.00   0.00\n",
      "v050      0.95   0.00\n",
      "v051      0.95   0.00\n",
      "v052      0.00   0.00\n",
      "v053      0.86   0.00\n",
      "v054      1.81   0.00\n",
      "v055      0.50   0.00\n",
      "v056      0.91   0.00\n",
      "v057      0.06   0.00\n",
      "v058      0.00   0.00\n",
      "v059      0.06   0.00\n",
      "v060      0.00   0.00\n",
      "v061      0.06   0.00\n",
      "v062      0.00   0.00\n",
      "v063      0.06   0.00\n",
      "v064      0.07   0.00\n",
      "v065      0.13   0.00\n",
      "v066      0.03   0.00\n",
      "v067      0.16   0.00\n",
      "v068      0.00   0.00\n",
      "v069      0.16   0.00\n",
      "v070      0.45   0.00\n",
      "v071      0.61   0.00\n",
      "v072      0.42   0.00\n",
      "v073      1.03   0.00\n",
      "v074      0.00   0.00\n",
      "v075      1.03   0.00\n",
      "v076      0.00   0.00\n",
      "v077      0.00   0.00\n",
      "v078      0.91   0.00\n",
      "step 0 backward\n",
      "name ty   data   grad\n",
      "v001 w1   0.24  -0.30\n",
      "v002 w2   0.07   0.16\n",
      "v003  b   0.00   0.00\n",
      "v004 w1  -0.27   0.02\n",
      "v005 w2   0.17  -0.16\n",
      "v006  b   0.00  -0.32\n",
      "v007 w1  -0.67   0.09\n",
      "v008 w2   0.65  -0.05\n",
      "v009  b   0.00   0.00\n",
      "v010  i   0.86  -0.08\n",
      "v011  i   0.03  -0.02\n",
      "v012  i  -0.05   0.17\n",
      "v013  i   0.50  -0.03\n",
      "v014      0.20  -0.33\n",
      "v015      0.20  -0.33\n",
      "v016      0.00  -0.33\n",
      "v017  a   0.20  -0.33\n",
      "v018      0.20  -0.33\n",
      "v019     -0.23   0.00\n",
      "v020     -0.23   0.00\n",
      "v021      0.01   0.00\n",
      "v022  a  -0.22   0.00\n",
      "v023      0.00   0.32\n",
      "v024     -0.14   0.50\n",
      "v025     -0.14   0.50\n",
      "v026      0.00   0.50\n",
      "v027  a  -0.14   0.50\n",
      "v028     -0.01   0.33\n",
      "v029     -0.01   0.33\n",
      "v030      0.03   0.33\n",
      "v031  a   0.02   0.33\n",
      "v032      0.02   0.33\n",
      "v033      0.01  -0.32\n",
      "v034      0.01  -0.32\n",
      "v035      0.09  -0.32\n",
      "v036  a   0.10  -0.32\n",
      "v037      0.10  -0.32\n",
      "v038     -0.01  -0.50\n",
      "v039     -0.01  -0.50\n",
      "v040      0.07  -0.50\n",
      "v041  a   0.05  -0.50\n",
      "v042      1.00  -0.07\n",
      "v043     -0.14   0.50\n",
      "v044      1.00   0.50\n",
      "v045      0.86   0.50\n",
      "v046      0.86   0.50\n",
      "v047     -1.00   0.03\n",
      "v048     -0.05   0.50\n",
      "v049      1.00   0.50\n",
      "v050      0.95   0.50\n",
      "v051      0.95   0.50\n",
      "v052      0.00   0.50\n",
      "v053      0.86   0.50\n",
      "v054      1.81   0.50\n",
      "v055      0.50   1.81\n",
      "v056      0.91   1.00\n",
      "v057      0.06   0.00\n",
      "v058      0.00   0.00\n",
      "v059      0.06   0.00\n",
      "v060      0.00   0.00\n",
      "v061      0.06   0.00\n",
      "v062      0.00   0.00\n",
      "v063      0.06   0.00\n",
      "v064      0.07   0.00\n",
      "v065      0.13   0.00\n",
      "v066      0.03   0.00\n",
      "v067      0.16   0.00\n",
      "v068      0.00   0.00\n",
      "v069      0.16   0.00\n",
      "v070      0.45   0.00\n",
      "v071      0.61   0.00\n",
      "v072      0.42   0.00\n",
      "v073      1.03   0.00\n",
      "v074      0.00   0.00\n",
      "v075      1.03   0.00\n",
      "v076      0.00   1.03\n",
      "v077      0.00   1.00\n",
      "v078      0.91   1.00\n",
      "step 0 loss 0.9065883811424296, accuracy 100.0%\n",
      "start step 1\n",
      "step 1 loss calc\n",
      "name ty   data   grad\n",
      "v001 w1   0.54  -0.30\n",
      "v002 w2  -0.09   0.16\n",
      "v003  b   0.00   0.00\n",
      "v004 w1  -0.28   0.02\n",
      "v005 w2   0.34  -0.16\n",
      "v006  b   0.32  -0.32\n",
      "v007 w1  -0.76   0.09\n",
      "v008 w2   0.70  -0.05\n",
      "v009  b   0.00   0.00\n",
      "v010  i   0.86  -0.08\n",
      "v011  i   0.03  -0.02\n",
      "v012  i  -0.05   0.17\n",
      "v013  i   0.50  -0.03\n",
      "v079      0.46   0.00\n",
      "v080      0.46   0.00\n",
      "v081     -0.00   0.00\n",
      "v082  a   0.46   0.00\n",
      "v083      0.46   0.00\n",
      "v084     -0.24   0.00\n",
      "v085      0.08   0.00\n",
      "v086      0.01   0.00\n",
      "v087  a   0.09   0.00\n",
      "v088      0.09   0.00\n",
      "v089     -0.35   0.00\n",
      "v090     -0.35   0.00\n",
      "v091      0.06   0.00\n",
      "v092  a  -0.29   0.00\n",
      "v093     -0.03   0.00\n",
      "v094     -0.03   0.00\n",
      "v095     -0.05   0.00\n",
      "v096  a  -0.07   0.00\n",
      "v097      0.00   0.00\n",
      "v098      0.01   0.00\n",
      "v099      0.34   0.00\n",
      "v100      0.17   0.00\n",
      "v101  a   0.51   0.00\n",
      "v102      0.51   0.00\n",
      "v103     -0.00   0.00\n",
      "v104      0.00   0.00\n",
      "v105      0.36   0.00\n",
      "v106  a   0.36   0.00\n",
      "v107      1.00   0.00\n",
      "v108     -0.29   0.00\n",
      "v109      1.00   0.00\n",
      "v110      0.71   0.00\n",
      "v111      0.71   0.00\n",
      "v112     -1.00   0.00\n",
      "v113     -0.36   0.00\n",
      "v114      1.00   0.00\n",
      "v115      0.64   0.00\n",
      "v116      0.64   0.00\n",
      "v117      0.00   0.00\n",
      "v118      0.71   0.00\n",
      "v119      1.36   0.00\n",
      "v120      0.50   0.00\n",
      "v121      0.68   0.00\n",
      "v122      0.29   0.00\n",
      "v123      0.00   0.00\n",
      "v124      0.29   0.00\n",
      "v125      0.01   0.00\n",
      "v126      0.30   0.00\n",
      "v127      0.00   0.00\n",
      "v128      0.30   0.00\n",
      "v129      0.08   0.00\n",
      "v130      0.38   0.00\n",
      "v131      0.11   0.00\n",
      "v132      0.49   0.00\n",
      "v133      0.11   0.00\n",
      "v134      0.60   0.00\n",
      "v135      0.58   0.00\n",
      "v136      1.18   0.00\n",
      "v137      0.49   0.00\n",
      "v138      1.66   0.00\n",
      "v139      0.00   0.00\n",
      "v140      1.66   0.00\n",
      "v141      0.00   0.00\n",
      "v142      0.00   0.00\n",
      "v143      0.68   0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/tmeng12/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/tmeng12/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "eog: symbol lookup error: /snap/core20/current/lib/x86_64-linux-gnu/libpthread.so.0: undefined symbol: __libc_pthread_init, version GLIBC_PRIVATE\n",
      "Failed to register: GDBus.Error:org.freedesktop.DBus.Error.NoReply: Message recipient disconnected from message bus without replying\n",
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/tmeng12/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/tmeng12/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "eog: symbol lookup error: /snap/core20/current/lib/x86_64-linux-gnu/libpthread.so.0: undefined symbol: __libc_pthread_init, version GLIBC_PRIVATE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 zero grad\n",
      "name ty   data   grad\n",
      "v001 w1   0.54   0.00\n",
      "v002 w2  -0.09   0.00\n",
      "v003  b   0.00   0.00\n",
      "v004 w1  -0.28   0.00\n",
      "v005 w2   0.34   0.00\n",
      "v006  b   0.32   0.00\n",
      "v007 w1  -0.76   0.00\n",
      "v008 w2   0.70   0.00\n",
      "v009  b   0.00   0.00\n",
      "v010  i   0.86  -0.08\n",
      "v011  i   0.03  -0.02\n",
      "v012  i  -0.05   0.17\n",
      "v013  i   0.50  -0.03\n",
      "v079      0.46   0.00\n",
      "v080      0.46   0.00\n",
      "v081     -0.00   0.00\n",
      "v082  a   0.46   0.00\n",
      "v083      0.46   0.00\n",
      "v084     -0.24   0.00\n",
      "v085      0.08   0.00\n",
      "v086      0.01   0.00\n",
      "v087  a   0.09   0.00\n",
      "v088      0.09   0.00\n",
      "v089     -0.35   0.00\n",
      "v090     -0.35   0.00\n",
      "v091      0.06   0.00\n",
      "v092  a  -0.29   0.00\n",
      "v093     -0.03   0.00\n",
      "v094     -0.03   0.00\n",
      "v095     -0.05   0.00\n",
      "v096  a  -0.07   0.00\n",
      "v097      0.00   0.00\n",
      "v098      0.01   0.00\n",
      "v099      0.34   0.00\n",
      "v100      0.17   0.00\n",
      "v101  a   0.51   0.00\n",
      "v102      0.51   0.00\n",
      "v103     -0.00   0.00\n",
      "v104      0.00   0.00\n",
      "v105      0.36   0.00\n",
      "v106  a   0.36   0.00\n",
      "v107      1.00   0.00\n",
      "v108     -0.29   0.00\n",
      "v109      1.00   0.00\n",
      "v110      0.71   0.00\n",
      "v111      0.71   0.00\n",
      "v112     -1.00   0.00\n",
      "v113     -0.36   0.00\n",
      "v114      1.00   0.00\n",
      "v115      0.64   0.00\n",
      "v116      0.64   0.00\n",
      "v117      0.00   0.00\n",
      "v118      0.71   0.00\n",
      "v119      1.36   0.00\n",
      "v120      0.50   0.00\n",
      "v121      0.68   0.00\n",
      "v122      0.29   0.00\n",
      "v123      0.00   0.00\n",
      "v124      0.29   0.00\n",
      "v125      0.01   0.00\n",
      "v126      0.30   0.00\n",
      "v127      0.00   0.00\n",
      "v128      0.30   0.00\n",
      "v129      0.08   0.00\n",
      "v130      0.38   0.00\n",
      "v131      0.11   0.00\n",
      "v132      0.49   0.00\n",
      "v133      0.11   0.00\n",
      "v134      0.60   0.00\n",
      "v135      0.58   0.00\n",
      "v136      1.18   0.00\n",
      "v137      0.49   0.00\n",
      "v138      1.66   0.00\n",
      "v139      0.00   0.00\n",
      "v140      1.66   0.00\n",
      "v141      0.00   0.00\n",
      "v142      0.00   0.00\n",
      "v143      0.68   0.00\n",
      "step 1 backward\n",
      "name ty   data   grad\n",
      "v001 w1   0.54  -0.33\n",
      "v002 w2  -0.09  -0.01\n",
      "v003  b   0.00  -0.38\n",
      "v004 w1  -0.28   0.32\n",
      "v005 w2   0.34  -0.17\n",
      "v006  b   0.32   0.00\n",
      "v007 w1  -0.76   0.23\n",
      "v008 w2   0.70  -0.21\n",
      "v009  b   0.00   0.00\n",
      "v010  i   0.86  -0.38\n",
      "v011  i   0.03   0.13\n",
      "v012  i  -0.05   0.27\n",
      "v013  i   0.50  -0.15\n",
      "v079      0.46  -0.38\n",
      "v080      0.46  -0.38\n",
      "v081     -0.00  -0.38\n",
      "v082  a   0.46  -0.38\n",
      "v083      0.46  -0.38\n",
      "v084     -0.24   0.35\n",
      "v085      0.08   0.35\n",
      "v086      0.01   0.35\n",
      "v087  a   0.09   0.35\n",
      "v088      0.09   0.35\n",
      "v089     -0.35   0.50\n",
      "v090     -0.35   0.50\n",
      "v091      0.06   0.50\n",
      "v092  a  -0.29   0.50\n",
      "v093     -0.03   0.00\n",
      "v094     -0.03   0.00\n",
      "v095     -0.05   0.00\n",
      "v096  a  -0.07   0.00\n",
      "v097      0.00   0.38\n",
      "v098      0.01  -0.35\n",
      "v099      0.34  -0.35\n",
      "v100      0.17  -0.35\n",
      "v101  a   0.51  -0.35\n",
      "v102      0.51  -0.35\n",
      "v103     -0.00  -0.50\n",
      "v104      0.00  -0.50\n",
      "v105      0.36  -0.50\n",
      "v106  a   0.36  -0.50\n",
      "v107      1.00  -0.14\n",
      "v108     -0.29   0.50\n",
      "v109      1.00   0.50\n",
      "v110      0.71   0.50\n",
      "v111      0.71   0.50\n",
      "v112     -1.00   0.18\n",
      "v113     -0.36   0.50\n",
      "v114      1.00   0.50\n",
      "v115      0.64   0.50\n",
      "v116      0.64   0.50\n",
      "v117      0.00   0.50\n",
      "v118      0.71   0.50\n",
      "v119      1.36   0.50\n",
      "v120      0.50   1.36\n",
      "v121      0.68   1.00\n",
      "v122      0.29   0.00\n",
      "v123      0.00   0.00\n",
      "v124      0.29   0.00\n",
      "v125      0.01   0.00\n",
      "v126      0.30   0.00\n",
      "v127      0.00   0.00\n",
      "v128      0.30   0.00\n",
      "v129      0.08   0.00\n",
      "v130      0.38   0.00\n",
      "v131      0.11   0.00\n",
      "v132      0.49   0.00\n",
      "v133      0.11   0.00\n",
      "v134      0.60   0.00\n",
      "v135      0.58   0.00\n",
      "v136      1.18   0.00\n",
      "v137      0.49   0.00\n",
      "v138      1.66   0.00\n",
      "v139      0.00   0.00\n",
      "v140      1.66   0.00\n",
      "v141      0.00   1.66\n",
      "v142      0.00   1.00\n",
      "v143      0.68   1.00\n",
      "step 1 loss 0.6796366507619458, accuracy 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/tmeng12/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "eog: symbol lookup error: /snap/core20/current/lib/x86_64-linux-gnu/libpthread.so.0: undefined symbol: __libc_pthread_init, version GLIBC_PRIVATE\n",
      "Failed to register: GDBus.Error:org.freedesktop.DBus.Error.ServiceUnknown: The name org.gnome.eog was not provided by any .service files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/tmeng12/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "eog: symbol lookup error: /snap/core20/current/lib/x86_64-linux-gnu/libpthread.so.0: undefined symbol: __libc_pthread_init, version GLIBC_PRIVATE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# optimization\n",
    "for k in range(number_of_iterations):\n",
    "    print(\"start step %d\" %k)\n",
    "    # pp.pprint(model.parameters())\n",
    "\n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    print(\"step %d loss calc\" %k)\n",
    "    print_all_values(total_loss)\n",
    "    dot=draw_dot(total_loss)\n",
    "    dot.render(\"images/opt_01_step%d_1loss\" % k , format=\"svg\", view=True)\n",
    "\n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    print(\"step %d zero grad\" %k)\n",
    "    print_all_values(total_loss)\n",
    "    dot=draw_dot(total_loss)\n",
    "    dot.render(\"images/opt_01_step%d_2zero\" % k , format=\"svg\", view=True)\n",
    "\n",
    "    total_loss.backward()\n",
    "    print(\"step %d backward\" %k)\n",
    "    print_all_values(total_loss)\n",
    "    dot=draw_dot(total_loss)\n",
    "    dot.render(\"images/opt_01_step%d_3back\" % k , format=\"svg\", view=True)\n",
    "    \n",
    "    # update (sgd)\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "    \n",
    "    # if k % 1 == 0:\n",
    "    #     print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n",
    "    print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
